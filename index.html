<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Paul Maria Scheikl</title>

    <meta name="author" content="Paul Maria Scheikl">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">

  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Paul Maria Scheikl
                </p>
                <p>I am a postdoc at Johns Hopkins University working under the guidance of <a href="https://engineering.jhu.edu/faculty/axel-krieger/">Axel Krieger</a> in the Laboratory for Computational Sensing and Robotics (<a href="https://lcsr.jhu.edu/">LCSR</a>).</p>
                <p style="text-align:center">
                  <a href="mailto:pscheik1@jhu.edu">Email</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?hl=en&user=MMm79XAAAAAJ">Scholar</a> &nbsp;/&nbsp;
                  <a href="https://github.com/ScheiklP/">Github</a>
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="images/PaulScheikl.jpg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/PaulScheikl.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <p>
                  My research interests lie at the intersection of robotics, computer vision, and machine learning.
                  I am particularly interested in developing algorithms for robot-assisted surgery, focusing on deformable object manipulation.
                  During my doctoral studies under the guidance of
                  <a href="https://www.sparc.tf.fau.de/person/prof-dr-franziska-mathis-ullrich/">Franziska Mathis-Ullrich</a> at the Friedrich-Alexander-University Erlangen-Nürnberg in Germany,
                  I worked on imitation learning, reinforcement learnig, semantic segmentation, deformable object simulation, and sim-to-real transfer.
                </p>
              </td>
            </tr>
          </tbody></table>

      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
              <img src='images/ludo.png' width=100%>
            </div>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://arxiv.org/abs/2411.08777">
              <span class="papertitle">LUDO: Low-Latency Understanding of Highly Deformable Objects using Point Cloud Occupancy Functions</span>
            </a>
            <br>
            Pit Henrich,
            Franziska Mathis-Ullrich,
            <strong>Paul Maria Scheikl</strong>
            <br>
            <em>Under Review</em>, 2024
            <p></p>
            <p>
            Reconstructs a complete deformable object, including deformed internal structures, from a single point cloud observation.
            We use the reconstructed object to plan a robotic path to puncture internal regions of interest.
            Deformable object reconstruction eliminates the need for deformable object registration!
            </p>
          </td>
        </tr>

        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
              <img src='images/ccc.png' width=100%>
            </div>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://ieeexplore.ieee.org/document/10611714">
              <span class="papertitle">Lens Capsule Tearing in Cataract Surgery using Reinforcement Learning</span>
            </a>
            <br>
            Rebekka Charlotte Peter,
            Steffen Peikert,
            Ludwig Haide,
            Doan Xuan Viet Pham,
            Tahar Chettaoui,
            Eleonora Tagliabue,
            <strong>Paul Maria Scheikl</strong>,
            Johannes Fauser,
            Matthias Hillenbrand,
            Gerhard Neumann,
            Franziska Mathis-Ullrich
            <br>
            <em>IEEE International Conference on Robotics and Automation (ICRA)</em>, 2024
            <p></p>
            <p>
            Demonstrates simulation and policy learning of lens capsule tearing in cataract surgery using reinforcement learning.
            </p>
          </td>
        </tr>

        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
              <img src='images/mpd.gif' width=100%>
            </div>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://ieeexplore.ieee.org/document/10480552">
              <span class="papertitle">Movement Primitive Diffusion: Learning Gentle Robotic Manipulation of Deformable Objects</span>
            </a>
            <br>
            <strong>Paul Maria Scheikl</strong>,
            <a href="https://alr.iar.kit.edu/21_261.php">Nicolas Schreiber</a>,
            Christoph Haas,
            <a href="https://alr.iar.kit.edu/21_221.php">Niklas Freymuth</a>,
            <a href="https://alr.iar.kit.edu/21_65.php">Gerhard Neumann</a>,
            <a href="https://rudolf.intuitive-robots.net/">Rudolf Lioutikov</a>,
            <a href="https://www.sparc.tf.fau.de/person/prof-dr-franziska-mathis-ullrich/">Franziska Mathis-Ullrich</a>.
            <br>
            <em>IEEE Robotics and Automation Letters (RA-L)</em>, 2024
            <br>
            <a href="https://github.com/ScheiklP/movement-primitive-diffusion">code</a>
            /
            <a href="https://scheiklp.github.io/movement-primitive-diffusion/">website</a>
            <p></p>
            <p>
            Combines the versatility of diffusion-based imitation learning with the high-quality motion generation capabilities of Probabilistic Dynamic Movement Primitives.
            Achieves gentle manipulation of deformable objects, while maintaining data efficiency critical for surgical applications where demonstration data is scarce.
            Evaluated in simulation and on real robotic hardware.
            </p>
          </td>
        </tr>

        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
              <img src='images/dor.gif' width=100%>
            </div>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://openaccess.thecvf.com/content/WACV2024/html/Henrich_Registered_and_Segmented_Deformable_Object_Reconstruction_From_a_Single_View_WACV_2024_paper.html">
              <span class="papertitle">Registered and Segmented Deformable Object Reconstruction From a Single View Point Cloud </span>
            </a>
            <br>
            <a href="https://www.sparc.tf.fau.de/person/pit-henrich/">Pit Henrich</a>,
            <a href="https://alr.iar.kit.edu/21_527.php">Balázs Gyenes</a>,
            <strong>Paul Maria Scheikl</strong>,
            <a href="https://alr.iar.kit.edu/21_65.php">Gerhard Neumann</a>,
            <a href="https://www.sparc.tf.fau.de/person/prof-dr-franziska-mathis-ullrich/">Franziska Mathis-Ullrich</a>.
            <br>
            <em>IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)</em>, 2024
            <br>
            <p>
                3D reconstruction and segmentation of deformable objects from a single view point cloud.
                Also introduces a simple sampling algorithm to generate better training data for occupancy learning.
            </p>
          </td>
        </tr>

        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
              <img src='images/lapgym.gif' width=100%>
            </div>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://jmlr.org/papers/v24/23-0207.html">
              <span class="papertitle">LapGym - An Open Source Framework for Reinforcement Learning in Robot-Assisted Laparoscopic Surgery</span>
            </a>
            <br>
            <strong>Paul Maria Scheikl</strong>,
            <a href="https://alr.iar.kit.edu/21_527.php">Balázs Gyenes</a>,
            Rayan Younis,
            Christoph Haas,
            <a href="https://alr.iar.kit.edu/21_65.php">Gerhard Neumann</a>,
            <a href="https://scholar.google.com/citations?hl=en&user=_2oVVGQAAAAJ">Martin Wagner</a>,
            <a href="https://www.sparc.tf.fau.de/person/prof-dr-franziska-mathis-ullrich/">Franziska Mathis-Ullrich</a>.
            <br>
            <em>Journal of Machine Learning Research (JMLR)</em>, 2023
            <br>
            code: <a href="https://github.com/ScheiklP/lap_gym">lap_gym</a>
            /
            <a href="https://github.com/ScheiklP/sofa_env">sofa_env</a>
            <p></p>
            <p>
            Reinforcement learning framework for robot-assisted laparoscopic surgery.
            Builds on the open-source, fast, interactive FEM simulation backend <a href="https://www.sofa-framework.org/"> SOFA</a>.
            Deformable object manipulation, topological changes (cutting), grasping, image observation modalities (RGB, depth, segmentation, point clouds).
            </p>
          </td>
        </tr>

        <tr onmouseout="ggns_stop()" onmouseover="ggns_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                    <div class="two" id='ggns_image'>
                        <img src='images/ggns.gif' width=100%>
                    </div>
                    <img src='images/ggns.png' width=100%>
                </div>
                <script type="text/javascript">
                    function ggns_start() {
                        document.getElementById('ggns_image').style.opacity = "1";
                    }

                    function ggns_stop() {
                        document.getElementById('ggns_image').style.opacity = "0";
                    }
                    ggns_stop()
                </script>
            </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://openreview.net/forum?id=jsZsEd8VEY">
              <span class="papertitle">Grounding Graph Network Simulators using Physical Sensor Observations</span>
            </a>
            <br>
            <a href="https://dmi.unibas.ch/de/personen/jonas-linkerhaegner/">Jonas Linkerhägner</a>,
            <a href="https://alr.iar.kit.edu/21_221.php">Niklas Freymuth</a>,
            <strong>Paul Maria Scheikl</strong>,
            <a href="https://www.sparc.tf.fau.de/person/prof-dr-franziska-mathis-ullrich/">Franziska Mathis-Ullrich</a>,
            <a href="https://alr.iar.kit.edu/21_65.php">Gerhard Neumann</a>.
            <br>
            <em>International Conference on Learning Representations (ICLR)</em>, 2023
            <br>
            <p>
            Integrate sensory information to ground Graph Network Simulators on real world observations.
            Predict the mesh state of deformable objects by utilizing point cloud data.
            </p>
          </td>
        </tr>

        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
              <img src='images/sim2real.gif' width=100%>
            </div>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://ieeexplore.ieee.org/abstract/document/9976185">
              <span class="papertitle">Sim-to-Real Transfer for Visual Reinforcement Learning of Deformable Object Manipulation for Robot-Assisted Surgery</span>
            </a>
            <br>
            <strong>Paul Maria Scheikl</strong>,
            <a href="https://www.linkedin.com/in/eleonora-tagliabue-720586141">Eleonora Tagliabue</a>,
            <a href="https://alr.iar.kit.edu/21_527.php">Balázs Gyenes</a>,
            <a href="https://scholar.google.com/citations?hl=en&user=_2oVVGQAAAAJ">Martin Wagner</a>,
            <a href="https://scholar.google.com/citations?hl=en&user=8jxdg6MAAAAJ">Diego Dall'Alba</a>,
            <a href="https://scholar.google.com/citations?hl=en&user=FsovWSkAAAAJ">Paolo Fiorini</a>,
            <a href="https://www.sparc.tf.fau.de/person/prof-dr-franziska-mathis-ullrich/">Franziska Mathis-Ullrich</a>.
            <br>
            <em>IEEE Robotics and Automation Letters (RA-L)</em>, 2022
            <br>
            <p>
            Training a visumotor policy for deformable object manipulation in simulation with reinforcement learning.
            Transferring the policy to the real world with the daVinci Research Kit using unpaired image-to-image translation.
            </p>
          </td>
        </tr>

        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
              <img src='images/coop.gif' width=100%>
            </div>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://ieeexplore.ieee.org/abstract/document/9636193">
              <span class="papertitle">Cooperative assistance in robotic surgery through multi-agent reinforcement learning</span>
            </a>
            <br>
            <strong>Paul Maria Scheikl</strong>,
            <a href="https://alr.iar.kit.edu/21_527.php">Balázs Gyenes</a>,
            Tornike Davitashvili,
            Rayan Younis,
            André Schulze,
            Beat P Müller-Stich,
            <a href="https://alr.iar.kit.edu/21_65.php">Gerhard Neumann</a>,
            <a href="https://scholar.google.com/citations?hl=en&user=_2oVVGQAAAAJ">Martin Wagner</a>,
            <a href="https://www.sparc.tf.fau.de/person/prof-dr-franziska-mathis-ullrich/">Franziska Mathis-Ullrich</a>.
            <br>
            <em>IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</em>, 2021
            <br>
            <p>
            Learns decentralized policies without a human in the loop with multi-agent reinforcement learning.
            Evaluates the learned policies in cooperation with a human surgeon for deformable object manipulation.
            </p>
          </td>
        </tr>

        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
              <img src='images/semseg.gif' width=100%>
            </div>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://www.degruyter.com/document/doi/10.1515/cdbme-2020-0016/html">
              <span class="papertitle">Deep learning for semantic segmentation of organs and tissues in laparoscopic surgery</span>
            </a>
            <br>
            <strong>Paul Maria Scheikl</strong>,
            Stefan Laschewski,
            Anna Kisilenko,
            Tornike Davitashvili,
            Benjamin Müller,
            Manuela Capek,
            Beat P Müller-Stich,
            <a href="https://scholar.google.com/citations?hl=en&user=_2oVVGQAAAAJ">Martin Wagner</a>,
            <a href="https://www.sparc.tf.fau.de/person/prof-dr-franziska-mathis-ullrich/">Franziska Mathis-Ullrich</a>.
            <br>
            <em>Current Directions in Biomedical Engineering (CDBE)</em>, 2020
            <br>
            <p>
            Evaluates several architectures and training strategies for semantic segmentation of organs and tissues in laparoscopic surgery.
            </p>
          </td>
        </tr>


      </tbody></table>


          <!-- <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody> -->
          <!--   <tr> -->
          <!--     <td> -->
          <!--       <h2>Miscellanea</h2> -->
          <!--     </td> -->
          <!--   </tr> -->
          <!-- </tbody></table> -->
          <!-- <table width="100%" align="center" border="0" cellpadding="20"><tbody> -->
            
          <!--   <tr> -->
          <!--     <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/cvf.jpg"></td> -->
          <!--     <td width="75%" valign="center"> -->
          <!--       <a href="Link">Text</a> -->
          <!--       <br> -->
          <!--       <a href="Link">Text</a> -->
          <!--     </td> -->
          <!--   </tr> -->

          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                  The website is based on the code from <a href="https://github.com/jonbarron/jonbarron_website">Jon Barron</a>
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
